import google.generativeai as genai
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from telegram import Update
from generate_plot import GeneratePlot
from latex_api import LatexAPI

class Gemini_api:
    def __init__(self):
        self.user_conversations = {}
        self.user_plot_data = {}
        self.plot_generator = GeneratePlot(None, None, self)  # Pass self as gemini_api
        self.latex_api = LatexAPI()

    async def start_command(self, update: Update, context: CallbackContext):
        """Lá»‡nh /start"""
        user_id = update.message.chat_id
        self.user_conversations[user_id] = []
        self.user_plot_data[user_id] = []
        await update.message.reply_text(
            "Xin chÃ o! TÃ´i lÃ  chatbot há»— trá»£ vá»›i Gemini AI.")

    @staticmethod
    def generate_ai_response(prompt, max_retries=3):
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)
        return response.text

    async def handle_message(self, update: Update, context: CallbackContext):
        """Xá»­ lÃ½ tin nháº¯n"""
        user_id = update.message.chat_id
        message = update.message.text
        print(f"ğŸ“© Nháº­n tin nháº¯n tá»« ngÆ°á»i dÃ¹ng ({user_id}): {message}")

        # Khá»Ÿi táº¡o bá»™ nhá»› náº¿u chÆ°a cÃ³
        if user_id not in self.user_conversations:
            self.user_conversations[user_id] = []
        if user_id not in self.user_plot_data:
            self.user_plot_data[user_id] = []

        # Xá»­ lÃ½ yÃªu cáº§u váº½ Ä‘á»“ thá»‹
        if "váº½" in message.lower() or "Ä‘á»“ thá»‹" in message.lower():
            self.user_conversations[user_id].append(f"NgÆ°á»i dÃ¹ng: {message}")
            description = message.replace("/plot", "").strip()
            await self.plot_generator.generate_plot(update, context, description)
            return
        
        # Xá»­ lÃ½ yÃªu cáº§u táº¡o bÃ¡o cÃ¡o
        if "váº½ report" in message.lower() or "váº½ bÃ¡o cÃ¡o" in message.lower():
            await self.generate_report_command(update, context)
            return

        # Xá»­ lÃ½ tin nháº¯n thÃ´ng thÆ°á»ng
        self.user_conversations[user_id].append(f"NgÆ°á»i dÃ¹ng: {message}")
        if len(self.user_conversations[user_id]) > 3:
            self.user_conversations[user_id].pop(0)

        conversation_history = "\n".join(self.user_conversations[user_id])
        prompt = f"""
        Vai trÃ² cá»§a báº¡n lÃ  má»™t nhÃ  phÃ¢n tÃ­ch kinh táº¿ chuyÃªn nghiá»‡p.
        - khÃ´ng tráº£ lá»i cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n kinh táº¿.
        - Tuyá»‡t Ä‘á»‘i khÃ´ng chÃ o ngÆ°á»i dÃ¹ng trong cÃ¢u nÃ³i ngoáº¡i trá»« ngÆ°á»i dÃ¹ng chÃ o báº¡n.
        - khi ngÆ°á»i dÃ¹ng chÃ o thÃ¬ chá»‰ giá»›i thiá»‡u ngáº¯n gá»n khÃ´ng quÃ¡ 4 cÃ¢u.
        - Chá»‰ cáº§n tráº£ lá»i trá»ng tÃ¢m vÃ o cÃ¢u há»i.
        - Tráº£ lá»i lá»‹ch sá»±.
        - TrÃ¬nh bÃ y Ä‘Æ¡n giáº£n, khÃ´ng in Ä‘áº­m cÃ¡c tá»«.
        - ÄÃ¡nh sá»‘ cÃ¡c Ã½ chÃ­nh mÃ  báº¡n muá»‘n tráº£ lá»i.
        - KhÃ´ng tráº£ lá»i quÃ¡ dÃ i dÃ²ng, khÃ´ng tráº£ lá»i quÃ¡ 200 tá»«.
        - báº¡n cÃ³ thá»ƒ váº½ Ä‘Æ°á»£c, náº¿u vÃ¬ má»™t lÃ½ do nÃ o Ä‘Ã³ mÃ  khÃ´ng váº½ Ä‘Æ°á»£c, thÃ¬ hÃ£y yÃªu cáº§u ngÆ°á»i dÃ¹ng yÃªu cáº§u váº½ láº¡i.
        - Báº¡n cÃ³ cÃ¡c chá»©c nÄƒng lÃ :
        + cung cáº¥p cÃ¡c kiáº¿n thá»©c vá» kinh táº¿ há»c
        + váº½ biá»ƒu Ä‘á»“ tá»« dá»¯ liá»‡u mÃ  ngÆ°á»i dÃ¹ng cung cáº¥p
        + táº¡o má»™t bÃ¡o cÃ¡o tÃ i chÃ­nh Ä‘Æ¡n giáº£n
        - KhÃ´ng tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¢n biá»‡t vÃ¹ng miá»n á»Ÿ Viá»‡t Nam.
        ÄÃ¢y lÃ  cuá»™c há»™i thoáº¡i trÆ°á»›c Ä‘Ã³:
        {conversation_history}
        NgÆ°á»i dÃ¹ng: {message}
        HÃ£y tráº£ lá»i má»™t cÃ¡ch chi tiáº¿t, logic vÃ  cÃ³ cÄƒn cá»© kinh táº¿.
        """

        response = await self.generate_ai_response(prompt)
        response = response.replace('*', '')
        print(f"ğŸ¤– Pháº£n há»“i tá»« Gemini: {response}")

        self.user_conversations[user_id].append(f"Bot: {response}")

        try:
            await update.message.reply_text(response)
            print("âœ… Gá»­i tin nháº¯n thÃ nh cÃ´ng!")
        except Exception as e:
            print(f"âŒ Lá»—i khi gá»­i tin nháº¯n: {e}")

    async def generate_report_command(self, update: Update, context: CallbackContext):
        """Generate and send PDF report"""
        user_id = update.message.chat_id
        await update.message.reply_text("Äang táº¡o bÃ¡o cÃ¡o kinh táº¿. Vui lÃ²ng chá»...")  # Added confirmation message

        await update.message.reply_text("ğŸ“Š Äang táº¡o bÃ¡o cÃ¡o kinh táº¿...")

        prompt = """
        Táº¡o má»™t bÃ¡o cÃ¡o kinh táº¿ chi tiáº¿t vá»›i cÃ¡c má»¥c:
        1. Tá»•ng quan kinh táº¿ vÄ© mÃ´
        2. CÃ¡c chá»‰ sá»‘ kinh táº¿ quan trá»ng
        3. PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng
        4. Dá»± bÃ¡o vÃ  khuyáº¿n nghá»‹
        
        Format bÃ¡o cÃ¡o theo cáº¥u trÃºc LaTeX.
        """
        
        report_content = self.generate_ai_response(prompt)
        pdf_buffer = await self.latex_api.generate_report(report_content)
        
        if pdf_buffer:
            await update.message.reply_document(
                document=pdf_buffer,
                filename=f'economic_report_{user_id}.pdf',
                caption="ğŸ¯ BÃ¡o cÃ¡o kinh táº¿ cá»§a báº¡n Ä‘Ã£ sáºµn sÃ ng!"
            )
        else:
            await update.message.reply_text("âŒ Xin lá»—i, cÃ³ lá»—i khi táº¡o bÃ¡o cÃ¡o PDF.")