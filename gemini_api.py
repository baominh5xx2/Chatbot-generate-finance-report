import google.generativeai as genai
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from telegram import Update
from datetime import datetime
import time
from generate_plot import GeneratePlot
from reading_csv import CSVReader  # Import the new CSV reader
import re
import io
import json
import os

class Gemini_api:
    def __init__(self):
        # Initialize with improved conversation history structure
        self.user_conversations = {}  # Store as dict with timestamp, role, and content
        self.user_plot_data = {}
        self.plot_generator = GeneratePlot(None, None, self)
        self.latex_generator = None
        self.max_history_length = 10  # Increased from 3 to retain more context
        self.history_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "conversation_history.json")
        self._load_history()
        self.csv_reader = CSVReader()  # Initialize CSV reader
        
    def _load_history(self):
        """Load conversation history from file if it exists"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    self.user_conversations = json.load(f)
                print(f"âœ… Loaded {len(self.user_conversations)} user conversation histories")
        except Exception as e:
            print(f"âŒ Error loading conversation history: {e}")
            self.user_conversations = {}
    
    def _save_history(self):
        """Save conversation history to file"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_conversations, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ Error saving conversation history: {e}")

    async def start_command(self, update: Update, context: CallbackContext):
        """Lá»‡nh /start"""
        user_id = update.message.chat_id
        self.user_conversations[user_id] = []
        self.user_plot_data[user_id] = []
        await update.message.reply_text(
            "Xin chÃ o! TÃ´i lÃ  chatbot há»— trá»£ vá»›i Gemini AI.")

    async def generate_ai_response(self, prompt, max_retries=3):
        for attempt in range(max_retries):
            try:
                model = genai.GenerativeModel("gemini-2.0-flash")
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                print(f"âŒ Lá»—i láº§n {attempt + 1}: {e}")
                if attempt == max_retries - 1:
                    return "Xin lá»—i, tÃ´i Ä‘ang gáº·p váº¥n Ä‘á» ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau."

    async def handle_message(self, update: Update, context: CallbackContext):
        """Xá»­ lÃ½ tin nháº¯n"""
        user_id = str(update.message.chat_id)  # Convert to string for JSON serialization
        current_time = time.time()
        
        # Handle file uploads (specifically CSV files)
        if update.message.document and update.message.document.file_name.endswith('.csv'):
            await self.handle_csv_upload(update, context)
            return
            
        # Handle text messages as before
        message = update.message.text
        print(f"ğŸ“© Nháº­n tin nháº¯n tá»« ngÆ°á»i dÃ¹ng ({user_id}): {message}")

        # Initialize chat history if needed with structured format
        if user_id not in self.user_conversations:
            self.user_conversations[user_id] = {
                "messages": [],
                "last_activity": current_time
            }
        
        if user_id not in self.user_plot_data:
            self.user_plot_data[user_id] = []

        # Update last activity time
        self.user_conversations[user_id]["last_activity"] = current_time
        
        # Handle CSV to PDF analysis request
        if message.lower().startswith("táº¡o pdf phÃ¢n tÃ­ch csv") or message.lower().startswith("phÃ¢n tÃ­ch pdf csv"):
            await self.generate_csv_analysis_pdf(update, context, message)
            return
            
        # Process special CSV-related commands
        if message.lower().startswith("xem dá»¯ liá»‡u csv"):
            preview = self.csv_reader.get_csv_preview(user_id)
            await update.message.reply_text(preview)
            return
            
        if message.lower().startswith("thÃ´ng tin cá»™t"):
            # Extract column name if provided
            parts = message.split("thÃ´ng tin cá»™t")
            column_name = parts[1].strip() if len(parts) > 1 and parts[1].strip() else None
            info = self.csv_reader.get_column_info(user_id, column_name)
            await update.message.reply_text(info)
            return
            
        if any(keyword in message.lower() for keyword in ["váº½ tá»« csv", "biá»ƒu Ä‘á»“ csv", "Ä‘á»“ thá»‹ csv"]):
            # Generate plot from CSV data
            buffer, result_msg = self.csv_reader.generate_quick_plot(user_id, message)
            
            if buffer:
                await update.message.reply_photo(photo=buffer, caption="ğŸ“Š Biá»ƒu Ä‘á»“ tá»« dá»¯ liá»‡u CSV")
                await update.message.reply_text("ğŸ’¡ Äá»ƒ váº½ biá»ƒu Ä‘á»“ phá»©c táº¡p hÆ¡n, hÃ£y mÃ´ táº£ cá»¥ thá»ƒ dá»¯ liá»‡u vÃ  loáº¡i biá»ƒu Ä‘á»“ báº¡n muá»‘n.")
            else:
                await update.message.reply_text(f"âŒ {result_msg}")
            return
        
        # Process special commands first
        # Get the most recent plot for this user
        if message.lower().startswith("xem code Ä‘á»“ thá»‹"):
            if user_id in self.plot_generator.user_plot_data and self.plot_generator.user_plot_data[user_id]:
                recent_plot = self.plot_generator.user_plot_data[user_id][-1]
                code = recent_plot.get("code", "KhÃ´ng cÃ³ mÃ£ nguá»“n")
                await update.message.reply_text(f"MÃ£ nguá»“n Ä‘á»“ thá»‹:\n```python\n{code}\n```")
            else:
                await update.message.reply_text("Báº¡n chÆ°a táº¡o báº¥t ká»³ Ä‘á»“ thá»‹ nÃ o.")
            return

        # Extended plot request detection
        plot_indicators = [
            "váº½", "Ä‘á»“ thá»‹", "biá»ƒu Ä‘á»“", "graph", "chart", "plot", "visualize", 
            "histogram", "scatter", "bar chart", "line chart", "biá»ƒu Ä‘á»“", "thá»‘ng kÃª",
            "visualization", "trend", "xu hÆ°á»›ng", "pie chart", "biá»ƒu Ä‘á»“ trÃ²n", "biá»ƒu Ä‘á»“ cá»™t"
        ]
        
        # Xá»­ lÃ½ yÃªu cáº§u váº½ Ä‘á»“ thá»‹ (vá»›i phÃ¡t hiá»‡n má»Ÿ rá»™ng)
        if any(indicator in message.lower() for indicator in plot_indicators) or message.lower().startswith("sá»­a"):
            # Add to conversation history so we remember the request was made
            self.user_conversations[user_id]["messages"].append({
                "role": "user",
                "content": message,
                "timestamp": current_time,
            })
            
            # Forward to plot generator
            description = message.replace("/plot", "").strip()
            await self.plot_generator.generate_plot(update, context, description)
            
            # Save the response to indicate we tried to generate a plot
            self.user_conversations[user_id]["messages"].append({
                "role": "assistant",
                "content": f"ÄÃ£ xá»­ lÃ½ yÃªu cáº§u váº½ biá»ƒu Ä‘á»“: '{description}'",
                "timestamp": time.time(),
            })
            return
        
        # Xá»­ lÃ½ yÃªu cáº§u Ä‘á»•i loáº¡i Ä‘á»“ thá»‹
        if message.lower().startswith("Ä‘á»•i loáº¡i Ä‘á»“ thá»‹") or "Ä‘á»•i Ä‘á»“ thá»‹" in message.lower():
            if user_id in self.plot_generator.user_plot_data and self.plot_generator.user_plot_data[user_id]:
                # Construct an edit request using the most recent plot description
                recent_plot = self.plot_generator.user_plot_data[user_id][-1]
                description = f"Sá»­a Ä‘á»“ thá»‹: {message}. Dá»±a trÃªn Ä‘á»“ thá»‹: {recent_plot.get('description', '')}"
                await self.plot_generator.generate_plot(update, context, description)
            else:
                await update.message.reply_text("Báº¡n chÆ°a táº¡o báº¥t ká»³ Ä‘á»“ thá»‹ nÃ o Ä‘á»ƒ chá»‰nh sá»­a.")
            return

        # Xá»­ lÃ½ yÃªu cáº§u táº¡o LaTeX hoáº·c PDF
        if any(keyword in message.lower() for keyword in ["latex", "táº¡o latex", "táº¡o pdf", "pdf"]):
            if self.latex_generator:
                # Clean the prompt by removing trigger keywords
                prompt = message.lower()
                for keyword in ["latex", "táº¡o latex", "táº¡o pdf", "pdf"]:
                    prompt = prompt.replace(keyword, "", 1)
                prompt = prompt.strip()
                
                await self.latex_generator.generate_latex(update, context, prompt)
                self.user_conversations[user_id]["messages"].append({
                    "role": "user",
                    "content": message,
                    "timestamp": current_time,
                })
                self.user_conversations[user_id]["messages"].append({
                    "role": "assistant",
                    "content": "ÄÃ£ táº¡o tÃ i liá»‡u PDF theo yÃªu cáº§u cá»§a báº¡n.",
                    "timestamp": time.time()
                })
                return

        # Handle regular messages - save with structured format
        user_message = {
            "role": "user",
            "content": message,
            "timestamp": current_time,
        }
        
        # Add user message to history
        self.user_conversations[user_id]["messages"].append(user_message)
        
        # Get conversation history - process the structured format for the Gemini prompt
        conversation_history = self._format_conversation_history(user_id)
        
        # Construct the prompt with enhanced context - add CSV data context if available
        csv_context = ""
        if user_id in self.csv_reader.user_csv_data and self.csv_reader.user_csv_data[user_id]:
            recent_file = self.csv_reader.user_csv_data[user_id][-1]
            csv_context = f"\nNgÆ°á»i dÃ¹ng Ä‘Ã£ táº£i lÃªn file CSV '{recent_file['filename']}' vá»›i {recent_file['shape'][0]} dÃ²ng vÃ  {recent_file['shape'][1]} cá»™t."
            csv_context += f"\nCÃ¡c cá»™t trong dá»¯ liá»‡u: {', '.join(recent_file['columns'])}"
            csv_context += "\nÄá»ƒ táº¡o bÃ¡o cÃ¡o PDF phÃ¢n tÃ­ch dá»¯ liá»‡u CSV nÃ y, ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ gÃµ 'táº¡o pdf phÃ¢n tÃ­ch csv'."
            
        prompt = f"""
        Vai trÃ² cá»§a báº¡n lÃ  má»™t nhÃ  phÃ¢n tÃ­ch kinh táº¿ chuyÃªn nghiá»‡p.
        - Tráº£ lá»i báº±ng tiáº¿ng viá»‡t.
        - Báº¡n hÃ£y giá»›i thiá»‡u mÃ¬nh lÃ  má»™t nhÃ  phÃ¢n tÃ­ch kinh táº¿ chuyÃªn nghiá»‡p.
        - khÃ´ng tráº£ lá»i cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n kinh táº¿.
        - Tuyá»‡t Ä‘á»‘i khÃ´ng chÃ o ngÆ°á»i dÃ¹ng trong cÃ¢u nÃ³i ngoáº¡i trá»« ngÆ°á»i dÃ¹ng chÃ o báº¡n.
        - khi ngÆ°á»i dÃ¹ng chÃ o thÃ¬ chá»‰ giá»›i thiá»‡u ngáº¯n gá»n khÃ´ng quÃ¡ 4 cÃ¢u.
        - Chá»‰ cáº§n tráº£ lá»i trá»ng tÃ¢m vÃ o cÃ¢u há»i.
        - Tráº£ lá»i lá»‹ch sá»±.
        - TrÃ¬nh bÃ y Ä‘Æ¡n giáº£n, khÃ´ng in Ä‘áº­m cÃ¡c tá»«.
        - ÄÃ¡nh sá»‘ cÃ¡c Ã½ chÃ­nh mÃ  báº¡n muá»‘n tráº£ lá»i.
        - KhÃ´ng tráº£ lá»i quÃ¡ dÃ i dÃ²ng, khÃ´ng tráº£ lá»i quÃ¡ 200 tá»«.
        - Khi ngÆ°á»i dÃ¹ng yÃªu cáº§u váº½ biá»ƒu Ä‘á»“, hÃ£y hÆ°á»›ng dáº«n há» dÃ¹ng cÃº phÃ¡p "váº½ biá»ƒu Ä‘á»“ [mÃ´ táº£]" Ä‘á»ƒ há»‡ thá»‘ng cÃ³ thá»ƒ xá»­ lÃ½ Ä‘Ãºng.
        - Báº¡n cÃ³ cÃ¡c chá»©c nÄƒng lÃ :
        + cung cáº¥p cÃ¡c kiáº¿n thá»©c vá» kinh táº¿ há»c
        + váº½ biá»ƒu Ä‘á»“ tá»« dá»¯ liá»‡u mÃ  ngÆ°á»i dÃ¹ng cung cáº¥p
        + táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch cÃ´ng ty chuyÃªn nghiá»‡p dÆ°á»›i dáº¡ng PDF báº±ng cÃ¡ch sá»­ dá»¥ng cÃº phÃ¡p "táº¡o pdf bÃ¡o cÃ¡o phÃ¢n tÃ­ch cÃ´ng ty [tÃªn cÃ´ng ty]" Ä‘á»ƒ nháº­n Ä‘Æ°á»£c bÃ¡o cÃ¡o PDF chuyÃªn nghiá»‡p.
        + phÃ¢n tÃ­ch file CSV báº±ng cÃ¡ch ngÆ°á»i dÃ¹ng upload file
        + táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u CSV dÆ°á»›i dáº¡ng PDF báº±ng cÃ¡ch sá»­ dá»¥ng cÃº phÃ¡p "táº¡o pdf phÃ¢n tÃ­ch csv" sau khi Ä‘Ã£ upload file CSV
        - KhÃ´ng tráº£ lá»i cÃ¡c cÃ¢u há»i vá» phÃ¢n biá»‡t vÃ¹ng miá»n á»Ÿ Viá»‡t Nam.
        {csv_context}
        ÄÃ¢y lÃ  cuá»™c há»™i thoáº¡i trÆ°á»›c Ä‘Ã³:
        {conversation_history}
        NgÆ°á»i dÃ¹ng: {message}
        HÃ£y tráº£ lá»i má»™t cÃ¡ch chi tiáº¿t, logic vÃ  cÃ³ cÄƒn cá»© kinh táº¿.
        """

        try:
            # Generate response
            response = await self.generate_ai_response(prompt)
            response = response.replace('*', '')
            print(f"ğŸ¤– Pháº£n há»“i tá»« Gemini: {response}")
            
            # Save bot response with structured format
            bot_message = {
                "role": "assistant", 
                "content": response,
                "timestamp": time.time()
            }
            
            self.user_conversations[user_id]["messages"].append(bot_message)
            
            # Trim conversation history if it gets too long
            self._trim_conversation_history(user_id)
            
            # Save history periodically
            self._save_history()
            
            await update.message.reply_text(response)
            print("âœ… Gá»­i tin nháº¯n thÃ nh cÃ´ng!")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi gá»­i tin nháº¯n: {e}")
            await update.message.reply_text("Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i. Vui lÃ²ng thá»­ láº¡i sau.")
    
    def _format_conversation_history(self, user_id):
        """Format conversation history for prompt context"""
        if user_id not in self.user_conversations:
            return ""
            
        # Get messages and check if we have any
        messages = self.user_conversations[user_id]["messages"]
        if not messages:
            return ""
            
        # Use only the most recent messages up to max_history_length
        recent_messages = messages[-self.max_history_length:]
        
        # Format messages as strings with roles
        formatted_messages = []
        for msg in recent_messages:
            role_label = "NgÆ°á»i dÃ¹ng" if msg["role"] == "user" else "Bot"
            formatted_messages.append(f"{role_label}: {msg['content']}")
            
        return "\n".join(formatted_messages)
    
    def _trim_conversation_history(self, user_id):
        """Trim conversation history to avoid it getting too long"""
        if user_id not in self.user_conversations:
            return
            
        messages = self.user_conversations[user_id]["messages"]
        max_history = self.max_history_length * 2  # Store more than we use in prompts
        
        if len(messages) > max_history:
            # Keep only the most recent messages
            self.user_conversations[user_id]["messages"] = messages[-max_history:]

    async def clear_history(self, update: Update, context: CallbackContext):
        """Clear conversation history for a user"""
        user_id = str(update.message.chat_id)
        
        if user_id in self.user_conversations:
            self.user_conversations[user_id]["messages"] = []
            await update.message.reply_text("ğŸ§¹ Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n Ä‘Ã£ Ä‘Æ°á»£c xÃ³a.")
        else:
            await update.message.reply_text("KhÃ´ng tÃ¬m tháº¥y lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n nÃ o.")
        
        self._save_history()

    async def handle_plot_callback(self, update: Update, context: CallbackContext):
        """Delegate plot callbacks to the plot_generator"""
        await self.plot_generator.handle_plot_callback(update, context)
        
    async def generate_csv_analysis_pdf(self, update: Update, context: CallbackContext, message):
        """Generate PDF analysis for CSV data"""
        user_id = str(update.message.chat_id)
        
        await update.message.reply_text("ğŸ”„ Äang phÃ¢n tÃ­ch dá»¯ liá»‡u CSV vÃ  táº¡o bÃ¡o cÃ¡o PDF...")
        
        # Get analysis data for the CSV
        analysis_data, status = self.csv_reader.prepare_csv_analysis_data(user_id)
        
        if status != "success" or not analysis_data:
            await update.message.reply_text(f"âŒ {status}")
            return
            
        try:
            # Extract analysis focus if specified
            focus_areas = []
            if "vá»" in message.lower():
                focus_part = message.lower().split("vá»", 1)[1].strip()
                focus_areas = [area.strip() for area in focus_part.split(",")]
            
            # Prepare prompt for LaTeX generation with CSV insights
            column_info = ", ".join(analysis_data["column_names"])
            insights = analysis_data["insights"]
            
            # Create a specialized prompt for the Gemini model
            prompt = f"""
            Táº¡o má»™t bÃ¡o cÃ¡o phÃ¢n tÃ­ch chuyÃªn nghiá»‡p vá» dá»¯ liá»‡u CSV cÃ³:
            - TÃªn file: {analysis_data['filename']}
            - Sá»‘ hÃ ng: {analysis_data['rows']}
            - Sá»‘ cá»™t: {analysis_data['columns']}
            - CÃ¡c cá»™t: {column_info}
            
            PhÃ¢n tÃ­ch chi tiáº¿t:
            {insights}
            
            BÃ¡o cÃ¡o cáº§n bao gá»“m:
            1. Trang bÃ¬a vá»›i tiÃªu Ä‘á» "BÃ¡o CÃ¡o PhÃ¢n TÃ­ch Dá»¯ Liá»‡u CSV: {analysis_data['filename']}" vÃ  ngÃ y táº¡o bÃ¡o cÃ¡o
            2. Má»¥c lá»¥c
            3. Tá»•ng quan vá» dá»¯ liá»‡u
            4. PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng cá»™t quan trá»ng
            5. PhÃ¡t hiá»‡n cÃ¡c máº«u vÃ  xu hÆ°á»›ng trong dá»¯ liá»‡u
            6. Äá» xuáº¥t cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch sÃ¢u hÆ¡n
            7. Káº¿t luáº­n
            
            {f'Táº­p trung vÃ o cÃ¡c khÃ­a cáº¡nh: {", ".join(focus_areas)}' if focus_areas else ''}
            
            Äá»‹nh dáº¡ng bÃ¡o cÃ¡o chuáº©n, chuyÃªn nghiá»‡p vÃ  dá»… Ä‘á»c.
            """
            
            # Use LaTeX generator to create PDF
            if self.latex_generator:
                await self.latex_generator.generate_latex(update, context, prompt, 
                                                         f"PhÃ¢n tÃ­ch CSV - {analysis_data['filename']}")
                
                # Record in conversation history
                self.user_conversations[user_id]["messages"].append({
                    "role": "user", 
                    "content": f"YÃªu cáº§u táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« file CSV: {analysis_data['filename']}",
                    "timestamp": time.time()
                })
                
                self.user_conversations[user_id]["messages"].append({
                    "role": "assistant", 
                    "content": f"ÄÃ£ táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« file CSV: {analysis_data['filename']}",
                    "timestamp": time.time()
                })
                
                self._save_history()
            else:
                await update.message.reply_text("âŒ KhÃ´ng thá»ƒ táº¡o bÃ¡o cÃ¡o PDF vÃ¬ chá»©c nÄƒng LaTeX chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o.")
                
        except Exception as e:
            print(f"âŒ Lá»—i khi táº¡o bÃ¡o cÃ¡o PDF: {e}")
            await update.message.reply_text(
                "âŒ ÄÃ£ xáº£y ra lá»—i khi táº¡o bÃ¡o cÃ¡o PDF. Vui lÃ²ng thá»­ láº¡i sau.")

    async def handle_csv_upload(self, update: Update, context: CallbackContext):
        """Handle CSV file uploads"""
        user_id = str(update.message.chat_id)
        document = update.message.document
        
        await update.message.reply_text("ğŸ”„ Äang xá»­ lÃ½ file CSV cá»§a báº¡n...")
        
        try:
            # Get file from Telegram
            file = await context.bot.get_file(document.file_id)
            file_content = await file.download_as_bytearray()
            
            # Process the CSV file
            result = self.csv_reader.process_csv(file_content, user_id)
            
            if result["success"]:
                # Send success message with summary
                await update.message.reply_text(
                    f"âœ… ÄÃ£ xá»­ lÃ½ file CSV thÃ nh cÃ´ng!\n\n"
                    f"ğŸ“„ TÃªn file: {document.file_name}\n"
                    f"ğŸ“Š ThÃ´ng tin:\n{result['summary']}\n\n"
                    f"ğŸ’¡ Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c lá»‡nh:\n"
                    f"â€¢ 'xem dá»¯ liá»‡u csv' - Ä‘á»ƒ xem báº£n xem trÆ°á»›c\n"
                    f"â€¢ 'thÃ´ng tin cá»™t [tÃªn_cá»™t]' - Ä‘á»ƒ xem chi tiáº¿t vá» má»™t cá»™t\n"
                    f"â€¢ 'váº½ biá»ƒu Ä‘á»“ csv [loáº¡i_biá»ƒu_Ä‘á»“] [tÃªn_cá»™t]' - Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ tá»« dá»¯ liá»‡u\n"
                    f"â€¢ 'táº¡o pdf phÃ¢n tÃ­ch csv' - Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch PDF chuyÃªn sÃ¢u"
                )
                
                # Add information to chat history
                if user_id in self.user_conversations:
                    self.user_conversations[user_id]["messages"].append({
                        "role": "user",
                        "content": f"ÄÃ£ táº£i lÃªn file CSV: {document.file_name}",
                        "timestamp": time.time()
                    })
                    
                    self.user_conversations[user_id]["messages"].append({
                        "role": "assistant",
                        "content": f"ÄÃ£ phÃ¢n tÃ­ch file CSV: {result['summary']}",
                        "timestamp": time.time()
                    })
                    
                    self._save_history()
            else:
                # Send error message
                await update.message.reply_text(
                    f"âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ file CSV: {result['error']}\n"
                    f"Vui lÃ²ng Ä‘áº£m báº£o file CSV cá»§a báº¡n Ä‘Ãºng Ä‘á»‹nh dáº¡ng vÃ  thá»­ láº¡i."
                )
                
        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ file CSV: {e}")
            await update.message.reply_text(
                "âŒ ÄÃ£ xáº£y ra lá»—i khi xá»­ lÃ½ file CSV cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i hoáº·c sá»­ dá»¥ng file khÃ¡c."
            )