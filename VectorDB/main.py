from sentence_transformers import SentenceTransformer
import torch
import pandas as pd
from pinecone import Pinecone
from tqdm import tqdm
import time

# âœ… KIá»‚M TRA VÃ€ CHáº Y MÃ” HÃŒNH TRÃŠN GPU (Náº¾U CÃ“)
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âœ… Äang cháº¡y trÃªn: {device.upper()}")

# âœ… Cáº¤U HÃŒNH BERT (Cháº¡y trÃªn GPU náº¿u cÃ³)
bert_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", device=device)

# âœ… Káº¾T Ná»I PINECONE
PINECONE_API_KEY = "pcsk_YgDiM_RwKYbFr23sS7RSEPjAwaQhf26BXzrSgUbeXdCeGX3mzusYUfgT3P58sQdp2uwMZ"
pc = Pinecone(api_key=PINECONE_API_KEY)

# âœ… Káº¾T Ná»I HOáº¶C Táº O INDEX TRONG PINECONE
index_name = "chatbot-ed"
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=384,  # KÃ­ch thÆ°á»›c vector cá»§a "all-MiniLM-L6-v2" lÃ  384
        metric="cosine"
    )
index = pc.Index(index_name)
print(f"âœ… ÄÃ£ káº¿t ná»‘i tá»›i index: {index_name}")
# âœ… Äá»ŒC FILE CSV
csv_path = "2022-Vietnam1.csv"
df = pd.read_csv(csv_path, encoding="utf-8-sig")

# âœ… Xá»¬ LÃ Dá»® LIá»†U: XÃ³a cá»™t trá»‘ng, Ä‘áº·t láº¡i tiÃªu Ä‘á»
column_headers = df.iloc[0].tolist()  # Láº¥y tiÃªu Ä‘á» tá»« hÃ ng Ä‘áº§u tiÃªn
df_cleaned = df.iloc[1:].reset_index(drop=True)  # XÃ³a hÃ ng Ä‘áº§u tiÃªn khá»i dá»¯ liá»‡u chÃ­nh

# âœ… HÃ€M Cáº®T NGáº®N VÄ‚N Báº¢N (náº¿u quÃ¡ dÃ i)
def truncate_text(text, max_chars=10000000000000):
    """Giá»›i háº¡n vÄƒn báº£n khÃ´ng quÃ¡ max_chars kÃ½ tá»±."""
    return text[:max_chars] + "..." if len(text) > max_chars else text

# âœ… CHIA NHá» Dá»® LIá»†U & Táº O EMBEDDINGS
batch_size = 1  # Sá»‘ dÃ²ng gá»­i má»—i láº§n
total_rows = len(df_cleaned)
output_file = "embeddings_data.txt"

with open(output_file, "w", encoding="utf-8") as f:
    for i in tqdm(range(0, total_rows, batch_size), desc="ğŸ”„ Äang táº¡o embeddings vá»›i BERT trÃªn GPU"):
        batch_vectors = []
        batch = df_cleaned.iloc[i:i+batch_size]

        for idx, row in batch.iterrows():
            # ğŸš€ Gá»™p dá»¯ liá»‡u Ä‘Ãºng format: "TÃªn cá»™t: GiÃ¡ trá»‹"
            text = " | ".join([f"{col_name}: {row.iloc[col_index]}" 
                               for col_index, col_name in enumerate(column_headers)])
            text = text.replace("#####", "MISSING_DATA")
            text = truncate_text(text)

            try:
                # ğŸš€ Táº¡o embedding tá»« BERT (Cháº¡y trÃªn GPU náº¿u cÃ³)
                embedding = bert_model.encode(text, convert_to_tensor=True, device=device).cpu().tolist()

                # ğŸš€ LÆ°u vÃ o danh sÃ¡ch vá»›i metadata
                batch_vectors.append((str(idx), embedding, {"data": text}))

                # âœ… Ghi vÃ o file txt
                f.write(f"ID: {idx} | Text: {text} | Embedding: {embedding}\n")

            except Exception as e:
                print(f"âš ï¸ Lá»—i xá»­ lÃ½ dÃ²ng {idx}: {str(e)}")
                continue

        # âœ… Gá»­i batch vÃ o Pinecone
        if batch_vectors:
            try:
                index.upsert(vectors=batch_vectors)
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi upsert vÃ o Pinecone: {str(e)}")
                continue

        time.sleep(1)

print(f"âœ… ÄÃ£ thÃªm {total_rows} vector embeddings vÃ o Pinecone thÃ nh cÃ´ng!")
print("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o:", output_file)
print(index.describe_index_stats())
